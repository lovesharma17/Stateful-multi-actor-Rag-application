{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install cassio\n",
        "!pip install langchain_text_splitters\n",
        "!pip install langchain_community\n",
        "!pip install langchain_huggingface"
      ],
      "metadata": {
        "id": "ZMaL9DOntx98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cassio\n",
        "\n",
        "## Connection of astra DB\n",
        "ASTRA_DB_APP_TOKENS = \"AstraCS:ZqZadBiesgIkmjTUFNFHHngJ:e8408cd2bd58d44e5d20982b12ee151e7187e13b27062b188f1b67703ab0d99c\"\n",
        "ASTRA_DB_ID = \"5d66db91-381d-49fa-a5a4-ef6081e0d88f\"\n",
        "cassio.init(token = ASTRA_DB_APP_TOKENS , database_id = ASTRA_DB_ID)"
      ],
      "metadata": {
        "id": "flzzMi0f_da9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Build Index\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "## docs to index\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "#load\n",
        "docs = [WebBaseLoader(url).load()[0] for url in urls]\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500 , chunk_overlap = 0)\n",
        "texts = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "GkjrQwZJ_kCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "zb9i2C-jAA7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Cassandra\n",
        "astra_vector_store = Cassandra(embedding = embeddings ,\n",
        "                               table_name = \"qa_mini_demo\",\n",
        "                               session = None,\n",
        "                               keyspace = None)"
      ],
      "metadata": {
        "id": "bAAtcKbFCBAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store.add_documents(texts)\n",
        "print(\"Inserted %i headlines.\" % len(texts))\n",
        "# To use the vector store as a retriever, you can do this:\n",
        "astra_retriever = astra_vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "stbzN9v8CtL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "astra_retriever.invoke(\"what is a agent\")"
      ],
      "metadata": {
        "id": "dD8G_BzeEwXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Langgraph application\n",
        "from typing import Literal\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel , Field"
      ],
      "metadata": {
        "id": "jZuTZxYZE8aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data model\n",
        "class RouteQuery(BaseModel):\n",
        "  \"\"\"Route a user query to the most relevant datasoucre. \"\"\"\n",
        "  datasoucre: Literal[\"vectorstore\" , \"wiki_search\"] = Field(\n",
        "      description = \"Given a user question choose to route it to a wikipedia or a vectorstore\"\n",
        "  )"
      ],
      "metadata": {
        "id": "6tuCLdrcFyfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import os\n",
        "groq_api_key = userdata.get('groq_api_key')\n"
      ],
      "metadata": {
        "id": "57ATD7NkIPKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(groq_api_key = groq_api_key , model_name = \"llama-3.1-8b-instant\")"
      ],
      "metadata": {
        "id": "_5ETV35eI4eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm_router = llm.with_structured_output(RouteQuery)"
      ],
      "metadata": {
        "id": "DvIB1Hm5JhXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "system = \"\"\" You are an expert at routing a user question to a vectorstore or wikipedia.\n",
        "The vectorstore contains documents related to agents , prompt engineering , adversarial attacks.\n",
        "Use the vectorstore to answer questions on the topics. otherwise , Use wiki-search,\"\"\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\" , system),\n",
        "        (\"human\" , \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "question_router = route_prompt | structured_llm_router\n"
      ],
      "metadata": {
        "id": "PUZryMZ4LKNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(question_router.invoke({\"question\" : \"what is a agent\"}))"
      ],
      "metadata": {
        "id": "q_7eFeenMXXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "2YImOjN3YMog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "wiki_wrap = WikipediaAPIWrapper()\n",
        "wiki = WikipediaQueryRun(api_wrapper = wiki_wrap)"
      ],
      "metadata": {
        "id": "Pd5TTnqIYZSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Aiagent Application using Langgraph\n",
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "  \"\"\"\n",
        "  Represent the state of our graph.\n",
        "  Attributes:\n",
        "     question : question\n",
        "     generation: LLM generation\n",
        "     documents: lisy of documents\n",
        "  \"\"\"\n",
        "  question: str\n",
        "  generation: str\n",
        "  documents: List[str]"
      ],
      "metadata": {
        "id": "M8i18RzcY5HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core import documents\n",
        "from langchain_core.tools import retriever\n",
        "from langchain.schema import Document\n",
        "\n",
        "def retrieve(state):\n",
        "  \"\"\"\n",
        "  Retrieve documents\n",
        "\n",
        "  Args:\n",
        "    state(dict) : The current graph state\n",
        "\n",
        "  Return:\n",
        "    state(dict) : New key added to state , documents , that contains the retrieved documents\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"---Retrieve---\")\n",
        "  question = state[\"question\"]\n",
        "\n",
        "  ## Retrieval\n",
        "  docs = retriever.invoke(question)\n",
        "  return {\"documents\": documents, \"question\":question}\n"
      ],
      "metadata": {
        "id": "g5AVlq4KtD2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wiki_search(state):\n",
        "  \"\"\"\n",
        "  wikkipedia search based on the rephrased question\n",
        "\n",
        "  Args:\n",
        "    state(dict) : The current graph state\n",
        "\n",
        "  Return:\n",
        "    state(dict) : Update documents key with appended web results\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"---Wikipedia---\")\n",
        "  print(\"---Hello---\")\n",
        "  question = state[\"question\"]\n",
        "  print(question)\n",
        "\n",
        "  ## wiki search\n",
        "  docs = wiki.invoke({\"query\": question})\n",
        "  wiki_results = docs\n",
        "  wiki_results = Document(page_content = wiki_results)\n",
        "  return {\"documents\": wiki_results, \"question\":question}"
      ],
      "metadata": {
        "id": "g5WCmtSNvp4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Edges ###\n",
        "\n",
        "\n",
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to wiki search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    if source.datasource == \"wiki_search\":\n",
        "        print(\"---ROUTE QUESTION TO Wiki SEARCH---\")\n",
        "        return \"wiki_search\"\n",
        "    elif source.datasource == \"vectorstore\":\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\""
      ],
      "metadata": {
        "id": "DUklpldSxFe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph import END , START , StateGraph\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "##Define the nodes\n",
        "workflow.add_node(\"wiki_search\" , function = wiki_search)\n",
        "workflow.add_node(\"vectorstore\" , function = retrieve)\n",
        "\n",
        "## Build Graph\n",
        "workflow.add_conditional_edges(\n",
        "    START ,\n",
        "    route_question,\n",
        "    {\"wiki_search\":\"wiki_search\"\n",
        "     ,\"vectorstore\": \"retrieve\"},\n",
        "\n",
        ")\n",
        "workflow.add_edge(\"retrieve\",END)\n",
        "workflow.add_edge(\"wiki_search\",END)\n",
        "\n",
        "## compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "-oafHRDxxj07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "eSzU8PFkzWO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\n",
        "    \"question\": \"Avengers\"\n",
        "}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value['documents'])"
      ],
      "metadata": {
        "id": "49T0pfgz6--3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}